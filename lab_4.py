# -*- coding: utf-8 -*-
"""lab_4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hI9ys5r9SbjzFkNb-dAUB-PqX3RjrQ3Z

## Task 1
"""

import numpy as np
import cv2
import matplotlib.pyplot as plt

np.random.seed(42)
np.set_printoptions(formatter={'float': '{:.3f}'.format})

points_3d = np.array([[x, y, 0] for x in np.linspace(-0.2, 0.2, 5) for y in np.linspace(-0.2, 0.2, 5)], dtype=np.float32)

x = points_3d[:, 0]
y = points_3d[:, 1]
z = points_3d[:, 2]

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(x, y, z, c='blue', label='Points')

ax.set_title("3D Visualization of Points")
ax.set_xlabel("X")
ax.set_ylabel("Y")
ax.set_zlabel("Z")
ax.legend()

plt.show()

"""Params Camera 1"""

image_size = (640, 480)

focal_length1 = 500
cx1, cy1 = image_size[0] // 2, image_size[1] // 2
camera_matrix1 = np.array([
    [focal_length1, 0, cx1],
    [0, focal_length1, cy1],
    [0, 0, 1]
], dtype=np.float32)

rvec1 = np.zeros(3, dtype=np.float32)
tvec1 = np.array([0.0, 0.0, 1.0], dtype=np.float32)

def rodrigues(rvec):
    if rvec.shape == (3, 1) or rvec.shape == (1, 3) or rvec.shape == (3,):
        theta = np.linalg.norm(rvec)
        if theta == 0:
            return np.eye(3)

        k = rvec / theta
        K = np.array([
            [0, -k[2], k[1]],
            [k[2], 0, -k[0]],
            [-k[1], k[0], 0]
        ])
        R = np.eye(3) + np.sin(theta) * K + (1 - np.cos(theta)) * np.dot(K, K)
        return R
    elif rvec.shape == (3, 3):
        R = rvec
        theta = np.arccos((np.trace(R) - 1) / 2)
        if np.isclose(theta, 0):
            return np.zeros((3, 1))

        k = np.array([
            R[2, 1] - R[1, 2],
            R[0, 2] - R[2, 0],
            R[1, 0] - R[0, 1]
        ]) / (2 * np.sin(theta))
        rvec = theta * k
        return rvec.reshape(3, 1)
    else:
        raise ValueError("Input must be a 3x1 rotation vector or a 3x3 rotation matrix.")

print(f'Comparison of Rodrigues methods: {((rodrigues(rvec1) - cv2.Rodrigues(rvec1)[0])**2).mean()}')

import numpy as np
import cv2
import matplotlib.pyplot as plt

def project_points(points_3d, camera_matrix, rvec, tvec):
    points_2d, _ = cv2.projectPoints(points_3d, rvec, tvec, camera_matrix, None)
    return points_2d.reshape(-1, 2)

def project_points_from_scratch(points_3d, camera_matrix, rvec, tvec):
    R, _ = cv2.Rodrigues(rvec)

    tvec = tvec.reshape(3, 1)

    points_cam = (R @ points_3d.T) + tvec
    points_cam = points_cam.T

    valid_mask = points_cam[:, 2] > 0
    if not np.any(valid_mask):
        raise ValueError("All points are behind the camera or on the camera plane.")

    valid_points_cam = points_cam[valid_mask]

    x = valid_points_cam[:, 0] / valid_points_cam[:, 2]
    y = valid_points_cam[:, 1] / valid_points_cam[:, 2]

    fx = camera_matrix[0, 0]
    fy = camera_matrix[1, 1]
    cx = camera_matrix[0, 2]
    cy = camera_matrix[1, 2]

    u = fx * x + cx
    v = fy * y + cy

    points_2d = np.full((points_3d.shape[0], 2), np.nan, dtype=np.float32)
    points_2d[valid_mask] = np.column_stack((u, v))

    return points_2d

"""## Task 2

"""

projected_points1 = project_points(points_3d, camera_matrix1, rvec1, tvec1)
projected_points12 = project_points_from_scratch(points_3d, camera_matrix1, rvec1, tvec1)

print(f'Comparison of project_points methods: {((projected_points12 - projected_points1)**2).mean()}')

image1 = np.ones((image_size[1], image_size[0], 3), dtype=np.uint8) * 255  # White image
for point in projected_points1:
    cv2.circle(image1, (int(point[0]), int(point[1])), 5, (0, 0, 255), -1)  # Draw points in red

plt.figure(figsize=(6, 6))
plt.imshow(image1)
plt.scatter(projected_points1[:, 0], projected_points1[:, 1], c='r', label="Camera 1")
plt.title("Original Camera 1")
plt.legend()
plt.axis('off')

plt.show()

"""#Task 3"""

object_points = [points_3d] * 10
image_points1 = []

for i in range(10):
    rvec = np.random.uniform(-1, 1, 3)
    tvec = np.random.uniform(-1, 1, 3)
    points = project_points(points_3d, camera_matrix1, rvec, tvec)
    image_points1.append(points + np.random.normal(0, 0.5, points.shape).astype(np.float32))

# image_points1 = [(projected_points1 + np.random.normal(0, 0.5, projected_points1.shape).astype(np.float32)) for _ in range(10)]

ret1, mtx1, dist1, rvecs1, tvecs1 = cv2.calibrateCamera(
    object_points, image_points1, image_size, camera_matrix1, None
)


print("\nCamera 1 Parameters:")
print("Initial Camera Matrix:")
print(camera_matrix1)
print("Calibrated Camera Matrix:")
print(mtx1)

"""#Task 4"""

focal_length2 = 400
cx2, cy2 = image_size[0] // 2 - 50, image_size[1] // 2 - 50
camera_matrix2 = np.array([
    [focal_length2, 0, cx2],
    [0, focal_length2, cy2],
    [0, 0, 1]
], dtype=np.float32)

rvec2 = np.array([0.1, 0.2, 0.3])
tvec2 = np.array([0.5, 0.1, 1])

projected_points2 = project_points(points_3d, camera_matrix2, rvec2, tvec2)

image2 = np.ones((image_size[1], image_size[0], 3), dtype=np.uint8) * 255
for point in projected_points2:
    cv2.circle(image2, (int(point[0]), int(point[1])), 5, (0, 255, 0), -1)

plt.figure(figsize=(6, 6))
plt.imshow(image2)
plt.scatter(projected_points2[:, 0], projected_points2[:, 1], c='g', label="Camera 2")
plt.title("Original Camera 2")
plt.legend()
plt.axis('off')

plt.show()

"""#Task 5"""

image_points2 = []

for i in range(10):
    rvec = np.random.uniform(-1, 1, 3)
    tvec = np.random.uniform(-1, 1, 3)
    points = project_points(points_3d, camera_matrix2, rvec, tvec)
    image_points2.append(points + np.random.normal(0, 0.5, projected_points2.shape).astype(np.float32))

# image_points2 = [projected_points2 + np.random.normal(0, 0.5, projected_points2.shape).astype(np.float32) for _ in range(10)]
ret2, mtx2, dist2, rvecs2, tvecs2 = cv2.calibrateCamera(object_points, image_points2, image_size, None, None)

print("\nCamera 2 Parameters:")
print("Initial Camera Matrix:")
print(camera_matrix2)
print("Calibrated Camera Matrix:")
print(np.round(mtx2))

"""#Task 6"""

ret_stereo, cm1, dc1, cm2, dc2, R, T, E, F = cv2.stereoCalibrate(
    object_points, image_points1, image_points2, mtx1, dist1, mtx2, dist2, image_size, None, None, None, None,
    flags=cv2.CALIB_FIX_INTRINSIC, criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-6)
)

print("\nCamera 1 Parameters:")
print("Initial Camera Matrix:")
print(camera_matrix1)
print("Stereo calibrated Camera Matrix:")
print(cm1)

print("\nCamera 2 Parameters:")
print("Initial Camera Matrix:")
print(camera_matrix2)
print("Stereo calibrated Camera Matrix:")
print(cm2)

"""#Task 7"""

def vector_product(t):
    return np.array([
        [0, -t[2], t[1]],
        [t[2], 0, -t[0]],
        [-t[1], t[0], 0]
    ])

T_ = vector_product(T.flatten())

E_custom = T_ @ R

F_custom = np.linalg.inv(cm2.T) @ E_custom @ np.linalg.inv(cm1)

F_custom_norm = F_custom / F_custom[-1, -1]

print(f'Essential matrix | stereoCalibrate:\n{E}')
print(f'\nEssential matrix | Custom:\n{E_custom}')

print(f'\n\nFundamental matrix | stereoCalibrate:\n{F}')
print(f'\nFundamental matrix | Custom:\n{F_custom_norm}')

"""#Task 8"""

points_3d = np.array([[x, y, 1] for x in np.linspace(-0.2, 0.2, 9) for y in np.linspace(-0.2, 0.2, 9)], dtype=np.float32)

projected_points1, _ = cv2.projectPoints(points_3d, rvec1, tvec1, camera_matrix1, None)
projected_points2, _ = cv2.projectPoints(points_3d, rvec2, tvec2, camera_matrix2, None)

pL = np.hstack((projected_points1.squeeze(), np.ones((len(points_3d), 1)) * points_3d[0, -1]))
pR = np.hstack((projected_points2.squeeze(), np.ones((len(points_3d), 1)) * points_3d[0, -1]))

for i in range(len(points_3d)):
    result = pR[i].T @ F @ pL[i]
    print(f"Point {i + 1}: pR^T * F * pL = {result:.6f}")

"""#Task 9"""

R1, _ = cv2.Rodrigues(rvec1)
R2, _ = cv2.Rodrigues(rvec2)

R = np.dot(R2, R1.T)
T = tvec2 - np.dot(R, tvec1)

R1_rect, R2_rect, P1, P2, Q, roi1, roi2 = cv2.stereoRectify(
    camera_matrix1, None, camera_matrix2, None, image_size, R, T, alpha=0
)

focal_length3 = (focal_length1 + focal_length2) / 2
camera_matrix3 = np.array([[focal_length3, 0, image_size[0] / 2],
                     [0, focal_length3, image_size[1] / 2],
                     [0, 0, 1]], dtype=np.float64)

H1 = np.dot(np.dot(camera_matrix3, R1_rect), np.linalg.inv(camera_matrix1))
H2 = np.dot(np.dot(camera_matrix3, R2_rect), np.linalg.inv(camera_matrix2))

print('Camera 1 Homography matrix:')
print(H1)

print('\n\nCamera2 Homography matrix:')
print(H2)

"""#Task 10"""

image1 = np.ones((image_size[1], image_size[0], 3), dtype=np.uint8) * 255
image2 = np.ones((image_size[1], image_size[0], 3), dtype=np.uint8) * 255

import numpy as np

def warp_perspective(image, H, output_size):
    width, height = output_size

    H_inv = np.linalg.inv(H)

    if len(image.shape) == 3:
        warped_image = np.zeros((height, width, image.shape[2]), dtype=image.dtype)
    else:
        warped_image = np.zeros((height, width), dtype=image.dtype)

    for y in range(height):
        for x in range(width):
            src_coords = np.dot(H_inv, np.array([x, y, 1]))
            src_coords /= src_coords[2]
            u, v = src_coords[:2]

            if 0 <= u < image.shape[1] - 1 and 0 <= v < image.shape[0] - 1:
                x0, y0 = int(u), int(v)
                x1, y1 = x0 + 1, y0 + 1

                a, b = u - x0, v - y0
                if len(image.shape) == 3:
                    pixel_value = (
                        (1 - a) * (1 - b) * image[y0, x0] +
                        a * (1 - b) * image[y0, x1] +
                        (1 - a) * b * image[y1, x0] +
                        a * b * image[y1, x1]
                    )
                else:
                    pixel_value = (
                        (1 - a) * (1 - b) * image[y0, x0] +
                        a * (1 - b) * image[y0, x1] +
                        (1 - a) * b * image[y1, x0] +
                        a * b * image[y1, x1]
                    )

                warped_image[y, x] = pixel_value

    return warped_image

wp_opencv = cv2.warpPerspective(image1, H1, image_size) / 255.0
wp_custom = warp_perspective(image1, H1, image_size) / 255.0

print(f'Comparison of warp_perspective methods: {((wp_custom - wp_opencv)**2).mean()}')
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.imshow(wp_opencv)
plt.title("Warp Perspective (OpenCV)")
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(wp_custom)
plt.title("Warp Perspective (Custom)")
plt.axis('off')

plt.tight_layout()
plt.show()

def perspective_transform(points, H):
    transformed_points = []
    for point in points:
        x, y = point
        homogeneous_point = np.array([x, y, 1.0])

        transformed_point = np.dot(H, homogeneous_point)

        transformed_point /= transformed_point[2]
        transformed_points.append(transformed_point[:2])

    return np.array(transformed_points)

projected_points1 = projected_points1.squeeze()

ps_opencv = cv2.perspectiveTransform(np.expand_dims(projected_points1, axis=0), H1).squeeze()
ps_custom = perspective_transform(projected_points1, H1).squeeze()

print(f'Comparison of warp_perspective methods: {((ps_custom - ps_opencv)**2).mean()}')

projected_points1, _ = cv2.projectPoints(points_3d, rvec1, tvec1, camera_matrix1, None)
projected_points2, _ = cv2.projectPoints(points_3d, rvec2, tvec2, camera_matrix2, None)
projected_points1 = projected_points1.squeeze()
projected_points2 = projected_points2.squeeze()

rectified_image1 = cv2.warpPerspective(image1, H1, image_size)
rectified_image2 = cv2.warpPerspective(image2, H2, image_size)

rectified_points1 = cv2.perspectiveTransform(np.expand_dims(projected_points1, axis=0), H1).squeeze()
rectified_points2 = cv2.perspectiveTransform(np.expand_dims(projected_points2, axis=0), H2).squeeze()

plt.figure(figsize=(18, 9))

plt.subplot(2, 2, 1)
plt.imshow(image1)
plt.scatter(projected_points1[:, 0], projected_points1[:, 1], c='r', label="Camera 1")
plt.title("Original Camera 1")
plt.legend()
plt.axis('off')

plt.subplot(2, 2, 2)
plt.imshow(image2)
plt.scatter(projected_points2[:, 0], projected_points2[:, 1], c='b', label="Camera 2")
plt.title("Original Camera 2")
plt.legend()
plt.axis('off')

plt.subplot(2, 2, 3)
plt.imshow(rectified_image1)
plt.scatter(rectified_points1[:, 0], rectified_points1[:, 1], c='r', label="Camera 1 Rectified")
plt.title("Rectified Camera 1")
plt.legend()
plt.axis('off')

plt.subplot(2, 2, 4)
plt.imshow(rectified_image2)
plt.scatter(rectified_points2[:, 0], rectified_points2[:, 1], c='b', label="Camera 2 Rectified")
plt.title("Rectified Camera 2")
plt.legend()
plt.axis('off')

plt.tight_layout()
plt.show()


print("Original y-coordinates (Camera 1):", projected_points1[:, 1])
print("Original y-coordinates (Camera 2):", projected_points2[:, 1])

for i, (y1, y2) in enumerate(zip(rectified_points1[:, 1], rectified_points2[:, 1])):
    print(f"Point {i}: Rectified y-coordinates (Camera 1, Camera 2): ({y1:.2f}, {y2:.2f})")